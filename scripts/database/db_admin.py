#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“ç®¡ç†å‘˜å·¥å…· - ç»Ÿä¸€çš„æ•°æ®åº“ç®¡ç†å’Œç»´æŠ¤å·¥å…·
æ•´åˆæ‰€æœ‰æ•°æ®åº“æ“ä½œåŠŸèƒ½ï¼Œæä¾›å®Œæ•´çš„æ•°æ®åº“ç®¡ç†è§£å†³æ–¹æ¡ˆ
"""

import os
import sys
import sqlite3
import json
import shutil
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass
from enum import Enum
import argparse

class BackupType(Enum):
    """å¤‡ä»½ç±»å‹æšä¸¾"""
    FULL = "full"
    INCREMENTAL = "incremental"
    SCHEMA_ONLY = "schema_only"
    DATA_ONLY = "data_only"

class MaintenanceAction(Enum):
    """ç»´æŠ¤æ“ä½œæšä¸¾"""
    VACUUM = "vacuum"
    REINDEX = "reindex"
    ANALYZE = "analyze"
    INTEGRITY_CHECK = "integrity_check"
    OPTIMIZE = "optimize"

@dataclass
class TableInfo:
    """è¡¨ä¿¡æ¯"""
    name: str
    row_count: int
    size_bytes: int
    last_modified: Optional[str] = None
    
    @property
    def size_mb(self) -> float:
        """å¤§å°(MB)"""
        return self.size_bytes / 1024 / 1024

@dataclass
class DatabaseInfo:
    """æ•°æ®åº“ä¿¡æ¯"""
    file_path: str
    file_size: int
    table_count: int
    total_rows: int
    created_time: datetime
    modified_time: datetime
    version: str
    
    @property
    def size_mb(self) -> float:
        """å¤§å°(MB)"""
        return self.file_size / 1024 / 1024

class DatabaseAdmin:
    """æ•°æ®åº“ç®¡ç†å‘˜"""
    
    def __init__(self, db_path: str = 'data/twitter_publisher.db'):
        self.db_path = db_path
        self.backup_dir = Path('backups')
        self.backup_dir.mkdir(exist_ok=True)
    
    def check_database_exists(self) -> bool:
        """æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨"""
        return os.path.exists(self.db_path)
    
    def get_database_info(self) -> Optional[DatabaseInfo]:
        """è·å–æ•°æ®åº“åŸºæœ¬ä¿¡æ¯"""
        if not self.check_database_exists():
            return None
        
        try:
            file_stat = os.stat(self.db_path)
            file_size = file_stat.st_size
            created_time = datetime.fromtimestamp(file_stat.st_ctime)
            modified_time = datetime.fromtimestamp(file_stat.st_mtime)
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # è·å–è¡¨æ•°é‡
            cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='table'")
            table_count = cursor.fetchone()[0]
            
            # è·å–æ€»è¡Œæ•°
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = cursor.fetchall()
            total_rows = 0
            
            for table in tables:
                table_name = table[0]
                try:
                    cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                    total_rows += cursor.fetchone()[0]
                except:
                    pass
            
            # è·å–SQLiteç‰ˆæœ¬
            cursor.execute("SELECT sqlite_version()")
            version = cursor.fetchone()[0]
            
            conn.close()
            
            return DatabaseInfo(
                file_path=self.db_path,
                file_size=file_size,
                table_count=table_count,
                total_rows=total_rows,
                created_time=created_time,
                modified_time=modified_time,
                version=version
            )
            
        except Exception as e:
            print(f"âŒ è·å–æ•°æ®åº“ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def get_table_info(self) -> List[TableInfo]:
        """è·å–æ‰€æœ‰è¡¨ä¿¡æ¯"""
        if not self.check_database_exists():
            return []
        
        tables = []
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # è·å–æ‰€æœ‰è¡¨å
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            table_names = [row[0] for row in cursor.fetchall()]
            
            for table_name in table_names:
                try:
                    # è·å–è¡Œæ•°
                    cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                    row_count = cursor.fetchone()[0]
                    
                    # ä¼°ç®—è¡¨å¤§å° (è¿™æ˜¯ä¸€ä¸ªè¿‘ä¼¼å€¼)
                    cursor.execute(f"SELECT * FROM {table_name} LIMIT 1")
                    sample_row = cursor.fetchone()
                    
                    if sample_row and row_count > 0:
                        # ä¼°ç®—æ¯è¡Œå¤§å°
                        row_size = sum(len(str(col)) if col else 0 for col in sample_row)
                        estimated_size = row_size * row_count
                    else:
                        estimated_size = 0
                    
                    table_info = TableInfo(
                        name=table_name,
                        row_count=row_count,
                        size_bytes=estimated_size
                    )
                    tables.append(table_info)
                    
                except Exception as e:
                    print(f"âš ï¸  è·å–è¡¨ {table_name} ä¿¡æ¯å¤±è´¥: {e}")
                    continue
            
            conn.close()
            
        except Exception as e:
            print(f"âŒ è·å–è¡¨ä¿¡æ¯å¤±è´¥: {e}")
        
        return tables
    
    def show_database_overview(self):
        """æ˜¾ç¤ºæ•°æ®åº“æ¦‚è§ˆ"""
        print(f"\nğŸ—„ï¸  æ•°æ®åº“æ¦‚è§ˆ")
        print("=" * 60)
        
        if not self.check_database_exists():
            print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.db_path}")
            return
        
        db_info = self.get_database_info()
        if not db_info:
            print(f"âŒ æ— æ³•è·å–æ•°æ®åº“ä¿¡æ¯")
            return
        
        print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {db_info.file_path}")
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {db_info.file_size:,} å­—èŠ‚ ({db_info.size_mb:.2f} MB)")
        print(f"ğŸ“‹ è¡¨æ•°é‡: {db_info.table_count}")
        print(f"ğŸ“ æ€»è®°å½•æ•°: {db_info.total_rows:,}")
        print(f"ğŸ• åˆ›å»ºæ—¶é—´: {db_info.created_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ•‘ ä¿®æ”¹æ—¶é—´: {db_info.modified_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ”§ SQLiteç‰ˆæœ¬: {db_info.version}")
        
        # æ˜¾ç¤ºè¡¨ä¿¡æ¯
        tables = self.get_table_info()
        if tables:
            print(f"\nğŸ“‹ è¡¨è¯¦æƒ…")
            print("-" * 60)
            print(f"{'è¡¨å':<20} {'è®°å½•æ•°':<10} {'å¤§å°(MB)':<10}")
            print("-" * 60)
            
            for table in sorted(tables, key=lambda t: t.row_count, reverse=True):
                print(f"{table.name:<20} {table.row_count:<10,} {table.size_mb:<10.2f}")
    
    def backup_database(self, backup_type: BackupType = BackupType.FULL, 
                       custom_name: Optional[str] = None) -> Optional[str]:
        """å¤‡ä»½æ•°æ®åº“"""
        if not self.check_database_exists():
            print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.db_path}")
            return None
        
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            if custom_name:
                backup_name = f"{custom_name}_{timestamp}"
            else:
                backup_name = f"backup_{backup_type.value}_{timestamp}"
            
            backup_path = self.backup_dir / f"{backup_name}.db"
            
            if backup_type == BackupType.FULL:
                # å®Œæ•´å¤‡ä»½
                shutil.copy2(self.db_path, backup_path)
                print(f"âœ… å®Œæ•´å¤‡ä»½å·²åˆ›å»º: {backup_path}")
            
            elif backup_type == BackupType.SCHEMA_ONLY:
                # ä»…å¤‡ä»½ç»“æ„
                conn_source = sqlite3.connect(self.db_path)
                conn_backup = sqlite3.connect(backup_path)
                
                # è·å–æ‰€æœ‰è¡¨çš„åˆ›å»ºè¯­å¥
                cursor = conn_source.cursor()
                cursor.execute("SELECT sql FROM sqlite_master WHERE type='table'")
                
                for row in cursor.fetchall():
                    if row[0]:  # è·³è¿‡Noneå€¼
                        conn_backup.execute(row[0])
                
                conn_backup.commit()
                conn_source.close()
                conn_backup.close()
                print(f"âœ… ç»“æ„å¤‡ä»½å·²åˆ›å»º: {backup_path}")
            
            elif backup_type == BackupType.DATA_ONLY:
                # ä»…å¤‡ä»½æ•°æ® (éœ€è¦å…ˆæœ‰ç»“æ„)
                print(f"âš ï¸  æ•°æ®å¤‡ä»½éœ€è¦ç›®æ ‡æ•°æ®åº“å·²æœ‰ç›¸åŒç»“æ„")
                return None
            
            return str(backup_path)
            
        except Exception as e:
            print(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
            return None
    
    def restore_database(self, backup_path: str, confirm: bool = False) -> bool:
        """æ¢å¤æ•°æ®åº“"""
        if not os.path.exists(backup_path):
            print(f"âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_path}")
            return False
        
        if not confirm:
            print(f"âš ï¸  æ­¤æ“ä½œå°†è¦†ç›–å½“å‰æ•°æ®åº“: {self.db_path}")
            response = input("ç¡®è®¤æ¢å¤? (yes/no): ")
            if response.lower() not in ['yes', 'y']:
                print("âŒ æ¢å¤æ“ä½œå·²å–æ¶ˆ")
                return False
        
        try:
            # å¤‡ä»½å½“å‰æ•°æ®åº“
            if self.check_database_exists():
                current_backup = self.backup_database(BackupType.FULL, "pre_restore")
                if current_backup:
                    print(f"ğŸ“‹ å½“å‰æ•°æ®åº“å·²å¤‡ä»½è‡³: {current_backup}")
            
            # æ¢å¤æ•°æ®åº“
            shutil.copy2(backup_path, self.db_path)
            print(f"âœ… æ•°æ®åº“å·²ä» {backup_path} æ¢å¤")
            return True
            
        except Exception as e:
            print(f"âŒ æ¢å¤å¤±è´¥: {e}")
            return False
    
    def list_backups(self):
        """åˆ—å‡ºæ‰€æœ‰å¤‡ä»½"""
        print(f"\nğŸ’¾ å¤‡ä»½åˆ—è¡¨")
        print("=" * 60)
        
        if not self.backup_dir.exists():
            print(f"ğŸ“­ å¤‡ä»½ç›®å½•ä¸å­˜åœ¨: {self.backup_dir}")
            return
        
        backup_files = list(self.backup_dir.glob('*.db'))
        
        if not backup_files:
            print(f"ğŸ“­ æ²¡æœ‰æ‰¾åˆ°å¤‡ä»½æ–‡ä»¶")
            return
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        backup_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)
        
        print(f"{'æ–‡ä»¶å':<30} {'å¤§å°(MB)':<10} {'åˆ›å»ºæ—¶é—´':<20}")
        print("-" * 60)
        
        for backup_file in backup_files:
            stat = backup_file.stat()
            size_mb = stat.st_size / 1024 / 1024
            created_time = datetime.fromtimestamp(stat.st_ctime)
            
            print(f"{backup_file.name:<30} {size_mb:<10.2f} {created_time.strftime('%Y-%m-%d %H:%M:%S'):<20}")
    
    def maintenance(self, action: MaintenanceAction) -> bool:
        """æ‰§è¡Œæ•°æ®åº“ç»´æŠ¤æ“ä½œ"""
        if not self.check_database_exists():
            print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.db_path}")
            return False
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            print(f"ğŸ”§ æ‰§è¡Œç»´æŠ¤æ“ä½œ: {action.value}")
            
            if action == MaintenanceAction.VACUUM:
                print(f"ğŸ“¦ æ­£åœ¨å‹ç¼©æ•°æ®åº“...")
                cursor.execute("VACUUM")
                print(f"âœ… æ•°æ®åº“å‹ç¼©å®Œæˆ")
            
            elif action == MaintenanceAction.REINDEX:
                print(f"ğŸ“‡ æ­£åœ¨é‡å»ºç´¢å¼•...")
                cursor.execute("REINDEX")
                print(f"âœ… ç´¢å¼•é‡å»ºå®Œæˆ")
            
            elif action == MaintenanceAction.ANALYZE:
                print(f"ğŸ“Š æ­£åœ¨åˆ†ææ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯...")
                cursor.execute("ANALYZE")
                print(f"âœ… ç»Ÿè®¡ä¿¡æ¯åˆ†æå®Œæˆ")
            
            elif action == MaintenanceAction.INTEGRITY_CHECK:
                print(f"ğŸ” æ­£åœ¨æ£€æŸ¥æ•°æ®åº“å®Œæ•´æ€§...")
                cursor.execute("PRAGMA integrity_check")
                results = cursor.fetchall()
                
                if results and results[0][0] == 'ok':
                    print(f"âœ… æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
                else:
                    print(f"âš ï¸  æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥å‘ç°é—®é¢˜:")
                    for result in results:
                        print(f"  - {result[0]}")
            
            elif action == MaintenanceAction.OPTIMIZE:
                print(f"âš¡ æ­£åœ¨ä¼˜åŒ–æ•°æ®åº“...")
                cursor.execute("PRAGMA optimize")
                print(f"âœ… æ•°æ®åº“ä¼˜åŒ–å®Œæˆ")
            
            conn.commit()
            conn.close()
            return True
            
        except Exception as e:
            print(f"âŒ ç»´æŠ¤æ“ä½œå¤±è´¥: {e}")
            return False
    
    def export_data(self, table_name: str, output_format: str = 'json', 
                   output_file: Optional[str] = None, limit: Optional[int] = None) -> bool:
        """å¯¼å‡ºæ•°æ®"""
        if not self.check_database_exists():
            print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.db_path}")
            return False
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name=?", (table_name,))
            if not cursor.fetchone():
                print(f"âŒ è¡¨ '{table_name}' ä¸å­˜åœ¨")
                return False
            
            # æ„å»ºæŸ¥è¯¢
            query = f"SELECT * FROM {table_name}"
            if limit:
                query += f" LIMIT {limit}"
            
            cursor.execute(query)
            rows = cursor.fetchall()
            
            # è·å–åˆ—å
            cursor.execute(f"PRAGMA table_info({table_name})")
            columns = [col[1] for col in cursor.fetchall()]
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            if not output_file:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                output_file = f"{table_name}_export_{timestamp}.{output_format}"
            
            # å¯¼å‡ºæ•°æ®
            if output_format.lower() == 'json':
                data = []
                for row in rows:
                    row_dict = dict(zip(columns, row))
                    data.append(row_dict)
                
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2, default=str)
            
            elif output_format.lower() == 'csv':
                import csv
                with open(output_file, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    writer.writerow(columns)  # å†™å…¥è¡¨å¤´
                    writer.writerows(rows)
            
            elif output_format.lower() == 'sql':
                with open(output_file, 'w', encoding='utf-8') as f:
                    # å†™å…¥è¡¨ç»“æ„
                    cursor.execute(f"SELECT sql FROM sqlite_master WHERE type='table' AND name='{table_name}'")
                    create_sql = cursor.fetchone()[0]
                    f.write(f"{create_sql};\n\n")
                    
                    # å†™å…¥æ•°æ®
                    for row in rows:
                        values = []
                        for value in row:
                            if value is None:
                                values.append('NULL')
                            elif isinstance(value, str):
                                escaped_value = value.replace("'", "''")
                                values.append(f"'{escaped_value}'")
                            else:
                                values.append(str(value))
                        
                        insert_sql = f"INSERT INTO {table_name} VALUES ({', '.join(values)});\n"
                        f.write(insert_sql)
            
            else:
                print(f"âŒ ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {output_format}")
                return False
            
            conn.close()
            print(f"âœ… æ•°æ®å·²å¯¼å‡ºè‡³: {output_file} ({len(rows)} æ¡è®°å½•)")
            return True
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
            return False
    
    def import_data(self, table_name: str, input_file: str, 
                   input_format: str = 'json', replace: bool = False) -> bool:
        """å¯¼å…¥æ•°æ®"""
        if not self.check_database_exists():
            print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.db_path}")
            return False
        
        if not os.path.exists(input_file):
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            return False
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name=?", (table_name,))
            table_exists = cursor.fetchone() is not None
            
            if not table_exists:
                print(f"âŒ è¡¨ '{table_name}' ä¸å­˜åœ¨")
                return False
            
            # å¦‚æœéœ€è¦æ›¿æ¢ï¼Œå…ˆæ¸…ç©ºè¡¨
            if replace:
                cursor.execute(f"DELETE FROM {table_name}")
                print(f"ğŸ—‘ï¸  è¡¨ '{table_name}' å·²æ¸…ç©º")
            
            # å¯¼å…¥æ•°æ®
            imported_count = 0
            
            if input_format.lower() == 'json':
                with open(input_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                if isinstance(data, list):
                    for item in data:
                        if isinstance(item, dict):
                            columns = list(item.keys())
                            values = list(item.values())
                            placeholders = ','.join(['?' for _ in values])
                            
                            insert_sql = f"INSERT INTO {table_name} ({','.join(columns)}) VALUES ({placeholders})"
                            cursor.execute(insert_sql, values)
                            imported_count += 1
            
            elif input_format.lower() == 'csv':
                import csv
                with open(input_file, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        columns = list(row.keys())
                        values = list(row.values())
                        placeholders = ','.join(['?' for _ in values])
                        
                        insert_sql = f"INSERT INTO {table_name} ({','.join(columns)}) VALUES ({placeholders})"
                        cursor.execute(insert_sql, values)
                        imported_count += 1
            
            else:
                print(f"âŒ ä¸æ”¯æŒçš„å¯¼å…¥æ ¼å¼: {input_format}")
                return False
            
            conn.commit()
            conn.close()
            print(f"âœ… æ•°æ®å·²å¯¼å…¥: {imported_count} æ¡è®°å½•")
            return True
            
        except Exception as e:
            print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
            return False
    
    def show_table_schema(self, table_name: str):
        """æ˜¾ç¤ºè¡¨ç»“æ„"""
        if not self.check_database_exists():
            print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.db_path}")
            return
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name=?", (table_name,))
            if not cursor.fetchone():
                print(f"âŒ è¡¨ '{table_name}' ä¸å­˜åœ¨")
                return
            
            print(f"\nğŸ“‹ è¡¨ç»“æ„: {table_name}")
            print("=" * 60)
            
            # è·å–è¡¨ä¿¡æ¯
            cursor.execute(f"PRAGMA table_info({table_name})")
            columns = cursor.fetchall()
            
            print(f"{'åˆ—å':<20} {'ç±»å‹':<15} {'éç©º':<5} {'é»˜è®¤å€¼':<15} {'ä¸»é”®':<5}")
            print("-" * 60)
            
            for col in columns:
                cid, name, col_type, notnull, default_value, pk = col
                notnull_str = "æ˜¯" if notnull else "å¦"
                pk_str = "æ˜¯" if pk else "å¦"
                default_str = str(default_value) if default_value is not None else ""
                
                print(f"{name:<20} {col_type:<15} {notnull_str:<5} {default_str:<15} {pk_str:<5}")
            
            # è·å–ç´¢å¼•ä¿¡æ¯
            cursor.execute(f"PRAGMA index_list({table_name})")
            indexes = cursor.fetchall()
            
            if indexes:
                print(f"\nğŸ“‡ ç´¢å¼•ä¿¡æ¯")
                print("-" * 40)
                for idx in indexes:
                    seq, name, unique, origin, partial = idx
                    unique_str = "å”¯ä¸€" if unique else "æ™®é€š"
                    print(f"  {name} ({unique_str})")
                    
                    # è·å–ç´¢å¼•åˆ—
                    cursor.execute(f"PRAGMA index_info({name})")
                    idx_cols = cursor.fetchall()
                    col_names = [col[2] for col in idx_cols]
                    print(f"    åˆ—: {', '.join(col_names)}")
            
            # è·å–å¤–é”®ä¿¡æ¯
            cursor.execute(f"PRAGMA foreign_key_list({table_name})")
            foreign_keys = cursor.fetchall()
            
            if foreign_keys:
                print(f"\nğŸ”— å¤–é”®ä¿¡æ¯")
                print("-" * 40)
                for fk in foreign_keys:
                    id, seq, table, from_col, to_col, on_update, on_delete, match = fk
                    print(f"  {from_col} -> {table}.{to_col}")
                    print(f"    æ›´æ–°: {on_update}, åˆ é™¤: {on_delete}")
            
            conn.close()
            
        except Exception as e:
            print(f"âŒ è·å–è¡¨ç»“æ„å¤±è´¥: {e}")
    
    def execute_query(self, query: str, params: Optional[Tuple] = None, 
                     fetch_results: bool = True, limit: int = 100) -> Optional[List[Tuple]]:
        """æ‰§è¡Œè‡ªå®šä¹‰æŸ¥è¯¢"""
        if not self.check_database_exists():
            print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.db_path}")
            return None
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            print(f"ğŸ” æ‰§è¡ŒæŸ¥è¯¢: {query[:100]}{'...' if len(query) > 100 else ''}")
            
            if params:
                cursor.execute(query, params)
            else:
                cursor.execute(query)
            
            if fetch_results:
                if query.strip().upper().startswith('SELECT'):
                    results = cursor.fetchmany(limit)
                    
                    if results:
                        # è·å–åˆ—å
                        column_names = [description[0] for description in cursor.description]
                        
                        print(f"\nğŸ“Š æŸ¥è¯¢ç»“æœ (æ˜¾ç¤ºå‰ {len(results)} æ¡)")
                        print("-" * 60)
                        
                        # æ˜¾ç¤ºè¡¨å¤´
                        header = " | ".join(f"{col:<15}" for col in column_names)
                        print(header)
                        print("-" * len(header))
                        
                        # æ˜¾ç¤ºæ•°æ®
                        for row in results:
                            row_str = " | ".join(f"{str(val):<15}" for val in row)
                            print(row_str)
                        
                        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šç»“æœ
                        cursor.fetchone()
                        if cursor.fetchone():
                            print(f"\n... è¿˜æœ‰æ›´å¤šç»“æœ (ä½¿ç”¨ --limit å‚æ•°æŸ¥çœ‹æ›´å¤š)")
                    else:
                        print(f"ğŸ“­ æŸ¥è¯¢æ— ç»“æœ")
                    
                    return results
                else:
                    # éSELECTæŸ¥è¯¢
                    affected_rows = cursor.rowcount
                    conn.commit()
                    print(f"âœ… æŸ¥è¯¢æ‰§è¡Œå®Œæˆï¼Œå½±å“ {affected_rows} è¡Œ")
                    return []
            else:
                conn.commit()
                print(f"âœ… æŸ¥è¯¢æ‰§è¡Œå®Œæˆ")
                return []
            
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {e}")
            return None
        finally:
            conn.close()

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="æ•°æ®åº“ç®¡ç†å‘˜å·¥å…· - ç»Ÿä¸€çš„æ•°æ®åº“ç®¡ç†å’Œç»´æŠ¤å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python db_admin.py --overview                           # æ˜¾ç¤ºæ•°æ®åº“æ¦‚è§ˆ
  python db_admin.py --backup full                       # å®Œæ•´å¤‡ä»½
  python db_admin.py --backup schema_only                # ä»…å¤‡ä»½ç»“æ„
  python db_admin.py --restore backups/backup_xxx.db     # æ¢å¤æ•°æ®åº“
  python db_admin.py --list-backups                      # åˆ—å‡ºå¤‡ä»½
  python db_admin.py --maintenance vacuum                # å‹ç¼©æ•°æ®åº“
  python db_admin.py --maintenance integrity_check       # å®Œæ•´æ€§æ£€æŸ¥
  python db_admin.py --export publishing_tasks json      # å¯¼å‡ºè¡¨æ•°æ®
  python db_admin.py --import publishing_tasks data.json # å¯¼å…¥è¡¨æ•°æ®
  python db_admin.py --schema publishing_tasks           # æ˜¾ç¤ºè¡¨ç»“æ„
  python db_admin.py --query "SELECT * FROM users"       # æ‰§è¡ŒæŸ¥è¯¢
        """
    )
    
    parser.add_argument(
        '--db-path',
        default='data/twitter_publisher.db',
        help='æ•°æ®åº“æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '--overview', '-o',
        action='store_true',
        help='æ˜¾ç¤ºæ•°æ®åº“æ¦‚è§ˆ'
    )
    
    parser.add_argument(
        '--backup', '-b',
        choices=[bt.value for bt in BackupType],
        help='å¤‡ä»½æ•°æ®åº“'
    )
    
    parser.add_argument(
        '--backup-name',
        help='è‡ªå®šä¹‰å¤‡ä»½åç§°'
    )
    
    parser.add_argument(
        '--restore', '-r',
        help='ä»å¤‡ä»½æ¢å¤æ•°æ®åº“'
    )
    
    parser.add_argument(
        '--list-backups',
        action='store_true',
        help='åˆ—å‡ºæ‰€æœ‰å¤‡ä»½'
    )
    
    parser.add_argument(
        '--maintenance', '-m',
        choices=[ma.value for ma in MaintenanceAction],
        help='æ‰§è¡Œç»´æŠ¤æ“ä½œ'
    )
    
    parser.add_argument(
        '--export',
        help='å¯¼å‡ºè¡¨æ•°æ® (è¡¨å)'
    )
    
    parser.add_argument(
        '--import',
        dest='import_table',
        help='å¯¼å…¥è¡¨æ•°æ® (è¡¨å)'
    )
    
    parser.add_argument(
        '--input-file',
        help='å¯¼å…¥æ•°æ®çš„è¾“å…¥æ–‡ä»¶'
    )
    
    parser.add_argument(
        '--output-file',
        help='å¯¼å‡ºæ•°æ®çš„è¾“å‡ºæ–‡ä»¶'
    )
    
    parser.add_argument(
        '--format',
        choices=['json', 'csv', 'sql'],
        default='json',
        help='å¯¼å…¥/å¯¼å‡ºæ ¼å¼'
    )
    
    parser.add_argument(
        '--replace',
        action='store_true',
        help='å¯¼å…¥æ—¶æ›¿æ¢ç°æœ‰æ•°æ®'
    )
    
    parser.add_argument(
        '--schema', '-s',
        help='æ˜¾ç¤ºè¡¨ç»“æ„'
    )
    
    parser.add_argument(
        '--query', '-q',
        help='æ‰§è¡Œè‡ªå®šä¹‰æŸ¥è¯¢'
    )
    
    parser.add_argument(
        '--limit', '-l',
        type=int,
        default=100,
        help='æŸ¥è¯¢ç»“æœé™åˆ¶'
    )
    
    parser.add_argument(
        '--confirm',
        action='store_true',
        help='è·³è¿‡ç¡®è®¤æç¤º'
    )
    
    args = parser.parse_args()
    
    try:
        admin = DatabaseAdmin(args.db_path)
        
        if args.overview:
            admin.show_database_overview()
        
        elif args.backup:
            backup_type = BackupType(args.backup)
            admin.backup_database(backup_type, args.backup_name)
        
        elif args.restore:
            admin.restore_database(args.restore, args.confirm)
        
        elif args.list_backups:
            admin.list_backups()
        
        elif args.maintenance:
            action = MaintenanceAction(args.maintenance)
            admin.maintenance(action)
        
        elif args.export:
            admin.export_data(
                args.export, 
                args.format, 
                args.output_file, 
                args.limit
            )
        
        elif args.import_table:
            if not args.input_file:
                print("âŒ å¯¼å…¥æ•°æ®éœ€è¦æŒ‡å®š --input-file")
                sys.exit(1)
            
            admin.import_data(
                args.import_table,
                args.input_file,
                args.format,
                args.replace
            )
        
        elif args.schema:
            admin.show_table_schema(args.schema)
        
        elif args.query:
            admin.execute_query(args.query, limit=args.limit)
        
        else:
            # é»˜è®¤æ˜¾ç¤ºæ¦‚è§ˆ
            admin.show_database_overview()
    
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ“ä½œå·²å–æ¶ˆ")
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()