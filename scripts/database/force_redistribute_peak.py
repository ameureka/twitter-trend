#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¼ºåˆ¶é‡æ–°åˆ†å¸ƒå³°å€¼æ—¶æ®µä»»åŠ¡è„šæœ¬

è¯¥è„šæœ¬ä¸“é—¨ç”¨äºå¤„ç†ç‰¹å®šæ—¶æ®µï¼ˆå¦‚09:00ï¼‰çš„é«˜å¯†åº¦ä»»åŠ¡ï¼Œ
å°†å…¶å¼ºåˆ¶åˆ†æ•£åˆ°å…¶ä»–æ—¶æ®µä»¥å®ç°æ›´å‡åŒ€çš„åˆ†å¸ƒã€‚
"""

import sys
import os
from pathlib import Path
from datetime import datetime, timedelta
import pytz
import random
from typing import List, Dict, Tuple, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from app.database.repository import PublishingTaskRepository
from app.database.models import PublishingTask
from app.database.database import DatabaseManager
from app.utils.enhanced_config import get_enhanced_config
from sqlalchemy import func

class ForcePeakRedistributor:
    """å³°å€¼æ—¶æ®µä»»åŠ¡é‡æ–°åˆ†å¸ƒå™¨"""
    
    def __init__(self, db_path: str = None):
        if db_path is None:
            # é»˜è®¤æ•°æ®åº“è·¯å¾„
            db_path = project_root / 'data' / 'twitter_publisher.db'
        
        # æ•°æ®åº“è¿æ¥
        db_url = f'sqlite:///{db_path}'
        self.db_manager = DatabaseManager(db_url)
        self.db_manager.create_tables()
        self.session = self.db_manager.get_session()
        
        # åˆå§‹åŒ–ä»“åº“
        self.task_repo = PublishingTaskRepository(self.session)
        
        # ä»é…ç½®æ–‡ä»¶è¯»å–å‚æ•°
        scheduling_config = get_enhanced_config().get('scheduling', {})
        self.blackout_hours = scheduling_config.get('blackout_hours', [0, 1, 2, 3, 4, 5, 6])
        self.min_interval_minutes = scheduling_config.get('interval_minutes_min', 180)
        
        print(f"é…ç½®ä¿¡æ¯: é™é»˜æ—¶é—´={self.blackout_hours}, æœ€å°é—´éš”={self.min_interval_minutes}åˆ†é’Ÿ")
    
    def get_peak_hour_tasks(self, target_hour: int = 9) -> List[Dict]:
        """è·å–æŒ‡å®šå°æ—¶çš„æ‰€æœ‰å¾…å‘å¸ƒä»»åŠ¡"""
        # ä½¿ç”¨SQLAlchemyæŸ¥è¯¢
        tasks = self.session.query(PublishingTask).filter(
            PublishingTask.status == 'pending',
            func.strftime('%H', func.datetime(PublishingTask.scheduled_at, '+8 hours')) == f'{target_hour:02d}'
        ).order_by(PublishingTask.priority.desc(), PublishingTask.scheduled_at.asc()).all()
        
        result = []
        for task in tasks:
            result.append({
                'id': task.id,
                'scheduled_at': task.scheduled_at,
                'content_data': task.content_data,
                'priority': task.priority
            })
        
        return result
    
    def get_available_target_hours(self) -> List[int]:
        """è·å–å¯ç”¨çš„ç›®æ ‡æ—¶æ®µï¼ˆé¿å¼€é™é»˜æ—¶é—´ï¼‰"""
        all_hours = list(range(24))
        available_hours = [h for h in all_hours if h not in self.blackout_hours]
        return available_hours
    
    def get_hour_task_count(self, hour: int) -> int:
        """è·å–æŒ‡å®šå°æ—¶çš„ä»»åŠ¡æ•°é‡"""
        count = self.session.query(PublishingTask).filter(
            PublishingTask.status == 'pending',
            func.strftime('%H', func.datetime(PublishingTask.scheduled_at, '+8 hours')) == f'{hour:02d}'
        ).count()
        
        return count
    
    def find_best_target_hours(self, exclude_hour: int = 9) -> List[Tuple[int, int]]:
        """æ‰¾åˆ°æœ€ä½³çš„ç›®æ ‡æ—¶æ®µï¼ˆä»»åŠ¡æ•°é‡æœ€å°‘çš„æ—¶æ®µï¼‰"""
        available_hours = self.get_available_target_hours()
        if exclude_hour in available_hours:
            available_hours.remove(exclude_hour)
        
        hour_counts = []
        for hour in available_hours:
            count = self.get_hour_task_count(hour)
            hour_counts.append((hour, count))
        
        # æŒ‰ä»»åŠ¡æ•°é‡æ’åºï¼Œä¼˜å…ˆé€‰æ‹©ä»»åŠ¡å°‘çš„æ—¶æ®µ
        hour_counts.sort(key=lambda x: x[1])
        return hour_counts
    
    def redistribute_peak_tasks(self, peak_hour: int = 9, target_count: int = 25, dry_run: bool = False):
        """å¼ºåˆ¶é‡æ–°åˆ†å¸ƒå³°å€¼æ—¶æ®µçš„ä»»åŠ¡"""
        print(f"\nå¼€å§‹å¼ºåˆ¶é‡æ–°åˆ†å¸ƒ {peak_hour}:00 æ—¶æ®µçš„ä»»åŠ¡...")
        
        # è·å–å³°å€¼æ—¶æ®µçš„æ‰€æœ‰ä»»åŠ¡
        peak_tasks = self.get_peak_hour_tasks(peak_hour)
        current_count = len(peak_tasks)
        
        print(f"å½“å‰ {peak_hour}:00 æ—¶æ®µæœ‰ {current_count} ä¸ªä»»åŠ¡")
        print(f"ç›®æ ‡: å‡å°‘åˆ° {target_count} ä¸ªä»»åŠ¡")
        
        if current_count <= target_count:
            print("ä»»åŠ¡æ•°é‡å·²ç»åœ¨ç›®æ ‡èŒƒå›´å†…ï¼Œæ— éœ€é‡æ–°åˆ†å¸ƒ")
            return {'moved': 0, 'skipped': current_count}
        
        # è®¡ç®—éœ€è¦ç§»åŠ¨çš„ä»»åŠ¡æ•°é‡
        tasks_to_move_count = current_count - target_count
        print(f"éœ€è¦ç§»åŠ¨ {tasks_to_move_count} ä¸ªä»»åŠ¡")
        
        # è·å–æœ€ä½³ç›®æ ‡æ—¶æ®µ
        target_hours = self.find_best_target_hours(exclude_hour=peak_hour)
        print(f"\nå¯ç”¨ç›®æ ‡æ—¶æ®µ: {[(h, c) for h, c in target_hours[:10]]}")
        
        if not target_hours:
            print("æ²¡æœ‰å¯ç”¨çš„ç›®æ ‡æ—¶æ®µ")
            return {'moved': 0, 'skipped': current_count}
        
        # é€‰æ‹©è¦ç§»åŠ¨çš„ä»»åŠ¡ï¼ˆä¼˜å…ˆç§»åŠ¨ä¼˜å…ˆçº§è¾ƒä½çš„ä»»åŠ¡ï¼‰
        tasks_to_move = sorted(peak_tasks, key=lambda x: (x['priority'], x['scheduled_at']))[:tasks_to_move_count]
        
        moved_count = 0
        skipped_count = 0
        
        for i, task in enumerate(tasks_to_move):
            # å¾ªç¯é€‰æ‹©ç›®æ ‡æ—¶æ®µï¼Œä¼˜å…ˆé€‰æ‹©ä»»åŠ¡å°‘çš„æ—¶æ®µ
            target_hour_info = target_hours[i % len(target_hours)]
            target_hour = target_hour_info[0]
            
            # è§£æåŸå§‹æ—¶é—´
            original_time = task['scheduled_at']
            if isinstance(original_time, str):
                original_time = datetime.fromisoformat(original_time.replace('Z', '+00:00'))
            
            # è®¡ç®—æ–°çš„æ—¶é—´ï¼ˆä¿æŒåŒä¸€å¤©ï¼Œåªæ”¹å˜å°æ—¶ï¼‰
            beijing_tz = pytz.timezone('Asia/Shanghai')
            if original_time.tzinfo is None:
                original_time = pytz.utc.localize(original_time)
            beijing_time = original_time.astimezone(beijing_tz)
            
            # åˆ›å»ºæ–°çš„æ—¶é—´ï¼ˆåŒä¸€å¤©ï¼Œæ–°çš„å°æ—¶ï¼Œéšæœºåˆ†é’Ÿï¼‰
            new_minute = random.randint(0, 59)
            new_second = random.randint(0, 59)
            
            new_beijing_time = beijing_time.replace(
                hour=target_hour,
                minute=new_minute,
                second=new_second
            )
            
            # è½¬æ¢å›UTC
            new_scheduled_at = new_beijing_time.astimezone(pytz.UTC)
            
            if not dry_run:
                try:
                    # æ›´æ–°ä»»åŠ¡æ—¶é—´
                    task_obj = self.task_repo.get_by_id(task['id'])
                    if task_obj:
                        # ç¡®ä¿new_scheduled_atæ˜¯datetimeå¯¹è±¡
                        if isinstance(new_scheduled_at, str):
                            new_scheduled_at = datetime.fromisoformat(new_scheduled_at.replace('Z', '+00:00'))
                        
                        task_obj.scheduled_at = new_scheduled_at
                        task_obj.updated_at = datetime.utcnow()
                        self.session.commit()
                        moved_count += 1
                        
                        if moved_count % 50 == 0:
                            print(f"å·²ç§»åŠ¨ {moved_count} ä¸ªä»»åŠ¡...")
                    else:
                        print(f"ä»»åŠ¡ {task['id']} ä¸å­˜åœ¨")
                        skipped_count += 1
                        
                except Exception as e:
                    print(f"ç§»åŠ¨ä»»åŠ¡ {task['id']} å¤±è´¥: {e}")
                    self.session.rollback()
                    skipped_count += 1
            else:
                print(f"[é¢„è§ˆ] ä»»åŠ¡ {task['id']}: {peak_hour}:00 -> {target_hour}:00")
                moved_count += 1
        
        print(f"\né‡æ–°åˆ†å¸ƒå®Œæˆ: ç§»åŠ¨äº† {moved_count} ä¸ªä»»åŠ¡ï¼Œè·³è¿‡äº† {skipped_count} ä¸ªä»»åŠ¡")
        return {'moved': moved_count, 'skipped': skipped_count}
    
    def analyze_distribution(self):
        """åˆ†æå½“å‰ä»»åŠ¡åˆ†å¸ƒ"""
        # ä½¿ç”¨SQLAlchemyæŸ¥è¯¢
        results = self.session.query(
            func.strftime('%H', func.datetime(PublishingTask.scheduled_at, '+8 hours')).label('hour'),
            func.count().label('count')
        ).filter(
            PublishingTask.status == 'pending'
        ).group_by(
            func.strftime('%H', func.datetime(PublishingTask.scheduled_at, '+8 hours'))
        ).order_by('hour').all()
        
        print("\nå½“å‰ä»»åŠ¡åˆ†å¸ƒï¼ˆåŒ—äº¬æ—¶é—´ï¼‰:")
        print("=" * 40)
        for hour, count in results:
            status = "âš ï¸" if count > 30 else "âœ…" if count <= 20 else "ğŸ”¶"
            print(f"{hour}:00 - {count:2d} ä¸ªä»»åŠ¡ {status}")

def main():
    redistributor = ForcePeakRedistributor()
    
    print("å¼ºåˆ¶å³°å€¼æ—¶æ®µä»»åŠ¡é‡æ–°åˆ†å¸ƒå·¥å…·")
    print("=" * 50)
    
    # å…ˆåˆ†æå½“å‰åˆ†å¸ƒ
    redistributor.analyze_distribution()
    
    print("\né€‰æ‹©æ“ä½œ:")
    print("1. é¢„è§ˆé‡æ–°åˆ†å¸ƒ (ä¸å®é™…ä¿®æ”¹)")
    print("2. æ‰§è¡Œé‡æ–°åˆ†å¸ƒ")
    print("3. ä»…åˆ†æå½“å‰åˆ†å¸ƒ")
    
    choice = input("\nè¯·é€‰æ‹© (1-3): ").strip()
    
    if choice == '1':
        redistributor.redistribute_peak_tasks(dry_run=True)
    elif choice == '2':
        redistributor.redistribute_peak_tasks(dry_run=False)
        print("\né‡æ–°åˆ†å¸ƒåçš„ä»»åŠ¡åˆ†å¸ƒ:")
        redistributor.analyze_distribution()
    elif choice == '3':
        pass  # å·²ç»åˆ†æè¿‡äº†
    else:
        print("æ— æ•ˆé€‰æ‹©")

if __name__ == '__main__':
    main()