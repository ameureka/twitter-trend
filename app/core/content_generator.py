# app/core/content_generator.py

import json
import os
import time
from typing import Dict, Any
from app.utils.logger import get_logger

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    genai = None

logger = get_logger(__name__)

class ContentGenerator:
    def __init__(self, use_ai: bool = False, gemini_api_key: str = None):
        self.use_ai = use_ai and GEMINI_AVAILABLE
        
        if self.use_ai:
            if not gemini_api_key:
                logger.warning("æœªæä¾›Gemini APIå¯†é’¥ï¼Œå°†ä½¿ç”¨ç›´æ¥æ¨¡å¼ç”Ÿæˆå†…å®¹")
                self.use_ai = False
            else:
                try:
                    genai.configure(api_key=gemini_api_key)
                    self.model = genai.GenerativeModel('gemini-pro')
                    logger.info("Gemini AIæ¨¡å¼å·²å¯ç”¨")
                except Exception as e:
                    logger.error(f"åˆå§‹åŒ–Geminiå¤±è´¥: {e}")
                    self.use_ai = False
        
        if not self.use_ai:
            logger.info("ä½¿ç”¨ç›´æ¥æ¨¡å¼ç”Ÿæˆå†…å®¹")

    def generate_tweet(self, metadata_path: str, video_filename: str, language: str = 'en', 
                      content_source_type: str = 'video', content_source_config: Dict[str, Any] = None) -> tuple[str, int]:
        """ä»å…ƒæ•°æ®æ–‡ä»¶ç”Ÿæˆæ¨æ–‡ã€‚è¿”å›(æ¨æ–‡å†…å®¹, ç”Ÿæˆè€—æ—¶æ¯«ç§’)"""
        start_time = time.time()
        
        # è¯¦ç»†è°ƒè¯•æ—¥å¿—
        logger.info(f"[CONTENT_GEN_DEBUG] å¼€å§‹ç”Ÿæˆæ¨æ–‡å†…å®¹")
        logger.info(f"[CONTENT_GEN_DEBUG] å‚æ•°: metadata_path={metadata_path}")
        logger.info(f"[CONTENT_GEN_DEBUG] å‚æ•°: video_filename={video_filename}")
        logger.info(f"[CONTENT_GEN_DEBUG] å‚æ•°: language={language}")
        logger.info(f"[CONTENT_GEN_DEBUG] å‚æ•°: content_source_type={content_source_type}")
        logger.info(f"[CONTENT_GEN_DEBUG] å‚æ•°: content_source_config={content_source_config}")
        
        try:
            with open(metadata_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            logger.info(f"[CONTENT_GEN_DEBUG] æˆåŠŸè¯»å–å…ƒæ•°æ®æ–‡ä»¶ï¼Œæ•°æ®é”®: {list(data.keys())}")
        except Exception as e:
            logger.error(f"[CONTENT_GEN_DEBUG] è¯»å–å…ƒæ•°æ®æ–‡ä»¶å¤±è´¥ {metadata_path}: {e}")
            raise ValueError(f"æ— æ³•è¯»å–å…ƒæ•°æ®æ–‡ä»¶: {e}")
        
        # æŸ¥æ‰¾å†…å®¹ä¿¡æ¯ï¼ˆæ”¯æŒä¸åŒç±»å‹çš„å†…å®¹æºï¼‰
        content_info = self._extract_content_info(data, video_filename, content_source_type)
        
        if not content_info:
            raise ValueError(f"åœ¨ {metadata_path} ä¸­æœªæ‰¾åˆ° {video_filename} çš„å…ƒæ•°æ®")

        # åº”ç”¨å†…å®¹æºç‰¹å®šçš„é…ç½®
        if content_source_config:
            content_info = self._apply_content_source_config(content_info, content_source_config)

        logger.info(f"[CONTENT_GEN_DEBUG] æå–çš„å†…å®¹ä¿¡æ¯: {content_info}")
        logger.info(f"[CONTENT_GEN_DEBUG] ä½¿ç”¨AIæ¨¡å¼: {self.use_ai}")
        
        if self.use_ai:
            logger.info(f"[CONTENT_GEN_DEBUG] ä½¿ç”¨Gemini AIç”Ÿæˆå†…å®¹")
            content = self._enhance_with_gemini(content_info, language, content_source_type)
        else:
            logger.info(f"[CONTENT_GEN_DEBUG] ä½¿ç”¨ç›´æ¥æ¨¡å¼ç”Ÿæˆå†…å®¹")
            content = self._generate_from_json_directly(content_info, language, content_source_type)
            
        generation_time = int((time.time() - start_time) * 1000)
        logger.info(f"[CONTENT_GEN_DEBUG] ç”Ÿæˆçš„æ¨æ–‡å†…å®¹: {content}")
        logger.info(f"[CONTENT_GEN_DEBUG] å†…å®¹ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {generation_time}ms")
        
        return content, generation_time
    
    def generate_tweet_from_data(self, content_data: Dict[str, Any], media_filename: str, language: str = 'en', 
                                content_source_type: str = 'video', content_source_config: Dict[str, Any] = None) -> tuple[str, int]:
        """ç›´æ¥ä»content_dataç”Ÿæˆæ¨æ–‡ã€‚è¿”å›(æ¨æ–‡å†…å®¹, ç”Ÿæˆè€—æ—¶æ¯«ç§’)"""
        start_time = time.time()
        
        # ç›´æ¥ä½¿ç”¨content_dataä½œä¸ºcontent_info
        content_info = content_data.copy()
        
        # åº”ç”¨å†…å®¹æºç‰¹å®šçš„é…ç½®
        if content_source_config:
            content_info = self._apply_content_source_config(content_info, content_source_config)

        if self.use_ai:
            content = self._enhance_with_gemini(content_info, language, content_source_type)
        else:
            content = self._generate_from_json_directly(content_info, language, content_source_type)
            
        generation_time = int((time.time() - start_time) * 1000)
        logger.info(f"å†…å®¹ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {generation_time}ms")
        
        return content, generation_time

    def extract_content_info_from_json(self, json_path: str, video_filename: str, language: str = 'en') -> Dict[str, Any] or None:
        """ä»JSONæ–‡ä»¶ä¸­æå–æŒ‡å®šè§†é¢‘çš„å†…å®¹ä¿¡æ¯"""
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError) as e:
            logger.error(f"è¯»å–JSONæ–‡ä»¶å¤±è´¥ {json_path}: {e}")
            return None
        
        # è·å–è§†é¢‘IDï¼ˆä¸å«æ‰©å±•åï¼‰
        video_id = os.path.splitext(video_filename)[0]
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç»¼åˆæŠ¥å‘Šæ–‡ä»¶æ ¼å¼ï¼ˆåŒ…å«resultsæ•°ç»„ï¼‰
        if 'results' in data and isinstance(data['results'], list):
            for result in data['results']:
                if result.get('video_id') == video_id:
                    # ä»markdown_contentä¸­æå–ä¿¡æ¯
                    return self._extract_from_markdown_content(result, language)
        
        # æŸ¥æ‰¾è§†é¢‘ä¿¡æ¯ï¼ˆåŸæœ‰æ ¼å¼ï¼‰
        if 'videos' in data:
            for video in data['videos']:
                if video.get('filename') == video_filename:
                    return video
        
        # ç›´æ¥æŸ¥æ‰¾
        return self._extract_content_info(data, video_filename)

    def _extract_from_markdown_content(self, result: Dict[str, Any], language: str = 'en') -> Dict[str, Any] or None:
        """ä»markdownå†…å®¹ä¸­æå–æ¨æ–‡ä¿¡æ¯"""
        try:
            markdown_content = result.get('markdown_content', '')
            if not markdown_content:
                return None
            
            # æå–æ ‡é¢˜ï¼ˆä»SEOä¼˜åŒ–æ–‡æ¡ˆéƒ¨åˆ†ï¼‰
            title_cn = ''
            title_en = ''
            description_cn = ''
            description_en = ''
            hashtags = []
            
            lines = markdown_content.split('\n')
            in_seo_section = False
            
            for i, line in enumerate(lines):
                line = line.strip()
                
                # æ£€æµ‹SEOä¼˜åŒ–æ–‡æ¡ˆéƒ¨åˆ†
                if '3.0 SEOä¼˜åŒ–æ–‡æ¡ˆ' in line:
                    in_seo_section = True
                    continue
                elif in_seo_section and line.startswith('### **4.0'):
                    break
                
                if in_seo_section:
                    # æ£€æŸ¥æ˜¯å¦åœ¨titleséƒ¨åˆ†
                    in_titles_section = False
                    in_descriptions_section = False
                    
                    # å‘å‰æŸ¥æ‰¾æœ€è¿‘çš„sectionæ ‡é¢˜
                    for j in range(i-1, -1, -1):
                        if 'titles' in lines[j].lower():
                            in_titles_section = True
                            break
                        elif 'descriptions' in lines[j].lower():
                            in_descriptions_section = True
                            break
                        elif 'hashtags' in lines[j].lower():
                            break
                    
                    # æå–ä¸­æ–‡æ ‡é¢˜
                    if 'ä¸­æ–‡:' in line and in_titles_section:
                        title_cn = line.split('ä¸­æ–‡:')[1].strip()
                        # ç§»é™¤hashtagséƒ¨åˆ†
                        if '#' in title_cn:
                            title_cn = title_cn.split('#')[0].strip()
                    
                    # æå–è‹±æ–‡æ ‡é¢˜
                    elif 'English:' in line and in_titles_section:
                        title_en = line.split('English:')[1].strip()
                        if '#' in title_en:
                            title_en = title_en.split('#')[0].strip()
                    
                    # æå–ä¸­æ–‡æè¿°
                    elif 'ä¸­æ–‡:' in line and in_descriptions_section:
                        description_cn = line.split('ä¸­æ–‡:')[1].strip()
                    
                    # æå–è‹±æ–‡æè¿°
                    elif 'English:' in line and in_descriptions_section:
                        description_en = line.split('English:')[1].strip()
                    
                    # æå–hashtags
                    elif 'hashtags' in line and '**hashtags' in line:
                        # æŸ¥æ‰¾ä¸‹ä¸€è¡Œçš„å†…å®¹
                        if i + 1 < len(lines):
                            hashtag_line = lines[i + 1].strip()
                            # æå–æ‰€æœ‰hashtags
                            import re
                            hashtag_matches = re.findall(r'#\w+', hashtag_line)
                            hashtags.extend([tag.replace('#', '') for tag in hashtag_matches])
            
            # æ ¹æ®languageå‚æ•°é€‰æ‹©åˆé€‚çš„titleå’Œdescription
            if language == 'en':
                # è‹±æ–‡æ¨¡å¼ï¼šä¼˜å…ˆä½¿ç”¨è‹±æ–‡ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ä¸­æ–‡
                selected_title = title_en or title_cn
                selected_description = description_en or description_cn
            else:
                # ä¸­æ–‡æ¨¡å¼ï¼šä¼˜å…ˆä½¿ç”¨ä¸­æ–‡ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨è‹±æ–‡
                selected_title = title_cn or title_en
                selected_description = description_cn or description_en
            
            # æ„å»ºè¿”å›çš„å†…å®¹ä¿¡æ¯
            content_info = {
                'video_id': result.get('video_id', ''),
                'title': selected_title,
                'title_cn': title_cn,
                'title_en': title_en,
                'description': selected_description,
                'description_cn': description_cn,
                'description_en': description_en,
                'hashtags': hashtags,
                'status': result.get('status', 'unknown'),
                'processing_time': result.get('processing_time', 0)
            }
            
            return content_info
            
        except Exception as e:
            logger.error(f"ä»markdownå†…å®¹æå–ä¿¡æ¯å¤±è´¥: {e}")
            return None

    def apply_source_config(self, content_info: Dict[str, Any], config: Dict[str, Any]) -> Dict[str, Any]:
        """åº”ç”¨æºé…ç½®åˆ°å†…å®¹ä¿¡æ¯"""
        result = content_info.copy()
        
        # å¤„ç†æ ‡é¢˜
        if 'title' in result:
            title = result['title']
            if config.get('title_prefix'):
                title = config['title_prefix'] + title
            if config.get('title_suffix'):
                title = title + config['title_suffix']
            
            # æ ‡é¢˜é•¿åº¦é™åˆ¶
            max_title_length = config.get('max_title_length')
            if max_title_length and len(title) > max_title_length:
                title = title[:max_title_length-3] + '...'
            
            result['title'] = title
        
        # å¤„ç†æè¿°
        if 'description' in result:
            description = result['description']
            if config.get('description_prefix'):
                description = config['description_prefix'] + description
            
            # æè¿°é•¿åº¦é™åˆ¶
            max_desc_length = config.get('max_description_length')
            if max_desc_length and len(description) > max_desc_length:
                description = description[:max_desc_length-3] + '...'
            
            result['description'] = description
        
        # å¤„ç†æ ‡ç­¾
        if 'additional_tags' in config:
            existing_tags = result.get('tags', [])
            if isinstance(existing_tags, str):
                existing_tags = [existing_tags]
            elif not isinstance(existing_tags, list):
                existing_tags = []
            
            additional_tags = config['additional_tags']
            if isinstance(additional_tags, str):
                additional_tags = [additional_tags]
            
            result['tags'] = existing_tags + additional_tags
        
        return result

    def format_tweet(self, content_info: Dict[str, Any], language: str) -> str:
        """æ ¼å¼åŒ–æ¨æ–‡å†…å®¹"""
        title = content_info.get('title', '')
        description = content_info.get('description', '')
        tags = content_info.get('tags', [])
        
        # å¤„ç†æ ‡ç­¾
        if isinstance(tags, list):
            # æ¸…ç†å’Œæ ¼å¼åŒ–æ ‡ç­¾
            formatted_tags = []
            for tag in tags:
                if tag:
                    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œæ›¿æ¢ç©ºæ ¼
                    clean_tag = ''.join(c for c in tag if c.isalnum() or c in ' -_')
                    clean_tag = clean_tag.replace(' ', '').replace('-', '').replace('_', '')
                    if clean_tag:
                        formatted_tags.append(f"#{clean_tag}")
            hashtag_str = ' '.join(formatted_tags)
        else:
            hashtag_str = str(tags) if tags else ''
        
        # æ ¹æ®è¯­è¨€è·å–å‰ç¼€
        if language == 'zh':
            prefix = 'ğŸ¬ '
        elif language == 'ja':
            prefix = 'ğŸ¬ '
        else:
            prefix = 'ğŸ¬ '
        
        # æ„å»ºæ¨æ–‡
        parts = []
        if prefix:
            parts.append(prefix.strip())
        
        if title:
            parts.append(title.strip())
        
        if description and description != title:
            # è®¡ç®—å¯ç”¨ç©ºé—´
            used_length = len(prefix) + len(title) + len(hashtag_str) + 10  # ç•™ä¸€äº›ç¼“å†²
            available_length = 280 - used_length
            
            if available_length > 20:
                if len(description) > available_length:
                    description = description[:available_length-3] + '...'
                parts.append(description.strip())
        
        if hashtag_str:
            parts.append(hashtag_str)
        
        tweet_content = '\n\n'.join(parts).strip()
        
        # ç¡®ä¿ä¸è¶…è¿‡280å­—ç¬¦
        if len(tweet_content) > 280:
            tweet_content = tweet_content[:277] + '...'
        
        return tweet_content

    def generate_content(self, video_filename: str, metadata_path: str, language: str = 'en', 
                        use_ai_enhancement: bool = False, gemini_api_key: str = None, 
                        source_config: Dict[str, Any] = None) -> str or None:
        """ç”Ÿæˆå†…å®¹çš„ç»Ÿä¸€æ¥å£"""
        try:
            # æå–å†…å®¹ä¿¡æ¯
            content_info = self.extract_content_info_from_json(metadata_path, video_filename, language)
            if not content_info:
                return None
            
            # åº”ç”¨æºé…ç½®
            if source_config:
                content_info = self.apply_source_config(content_info, source_config)
            
            # å¦‚æœå¯ç”¨AIå¢å¼º
            if use_ai_enhancement and gemini_api_key:
                # ä¸´æ—¶å¯ç”¨AIæ¨¡å¼
                original_use_ai = self.use_ai
                try:
                    if not self.use_ai:
                        genai.configure(api_key=gemini_api_key)
                        self.model = genai.GenerativeModel('gemini-pro')
                        self.use_ai = True
                    
                    return self._enhance_with_gemini(content_info, language)
                except Exception as e:
                    logger.error(f"AIå¢å¼ºå¤±è´¥ï¼Œé™çº§åˆ°ç›´æ¥æ¨¡å¼: {e}")
                    return self.format_tweet(content_info, language)
                finally:
                    self.use_ai = original_use_ai
            else:
                return self.format_tweet(content_info, language)
                
        except Exception as e:
            logger.error(f"å†…å®¹ç”Ÿæˆå¤±è´¥: {e}")
            return None

    def _extract_content_info(self, data: Dict[str, Any], filename: str, content_type: str = 'video') -> Dict[str, Any] or None:
        """ä»JSONæ•°æ®ä¸­æå–å†…å®¹ä¿¡æ¯ã€‚"""
        # å°è¯•å¤šç§é”®åæ¨¡å¼
        possible_keys = [
            filename,  # å®Œæ•´æ–‡ä»¶å
            os.path.splitext(filename)[0],  # ä¸å«æ‰©å±•å
        ]
        
        for key in possible_keys:
            if key in data:
                return data[key]
                
        # å¦‚æœç›´æ¥æŸ¥æ‰¾å¤±è´¥ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
        file_base = os.path.splitext(filename)[0]
        for key, value in data.items():
            if file_base in key or key in file_base:
                return value
                
        return None
    
    def _apply_content_source_config(self, content_info: Dict[str, Any], config: Dict[str, Any]) -> Dict[str, Any]:
        """åº”ç”¨å†…å®¹æºç‰¹å®šçš„é…ç½®ã€‚"""
        # åº”ç”¨æ¨¡æ¿è¦†ç›–
        if 'title_template' in config and config['title_template']:
            content_info['title'] = config['title_template'].format(**content_info)
            
        if 'description_template' in config and config['description_template']:
            content_info['description'] = config['description_template'].format(**content_info)
            
        # æ·»åŠ é¢å¤–çš„æ ‡ç­¾
        if 'additional_hashtags' in config:
            existing_hashtags = content_info.get('hashtags', [])
            if isinstance(existing_hashtags, str):
                existing_hashtags = [existing_hashtags]
            elif not isinstance(existing_hashtags, list):
                existing_hashtags = []
                
            additional_hashtags = config['additional_hashtags']
            if isinstance(additional_hashtags, str):
                additional_hashtags = [additional_hashtags]
                
            content_info['hashtags'] = existing_hashtags + additional_hashtags
            
        return content_info

    def _generate_from_json_directly(self, info: Dict[str, Any], language: str, content_type: str = 'video') -> str:
        """ç›´æ¥ä»JSONç»„åˆæ¨æ–‡ã€‚"""
        logger.info(f"[CONTENT_GEN_DEBUG] _generate_from_json_directly å¼€å§‹")
        logger.info(f"[CONTENT_GEN_DEBUG] è¾“å…¥å‚æ•° - info: {info}")
        logger.info(f"[CONTENT_GEN_DEBUG] è¾“å…¥å‚æ•° - language: {language}")
        logger.info(f"[CONTENT_GEN_DEBUG] è¾“å…¥å‚æ•° - content_type: {content_type}")
        
        title = info.get('title', '')
        description = info.get('description', '')
        hashtags = info.get('hashtags', [])
        keywords = info.get('keywords', [])
        
        logger.info(f"[CONTENT_GEN_DEBUG] æå–çš„å­—æ®µ - title: {title}")
        logger.info(f"[CONTENT_GEN_DEBUG] æå–çš„å­—æ®µ - description: {description}")
        logger.info(f"[CONTENT_GEN_DEBUG] æå–çš„å­—æ®µ - hashtags: {hashtags}")
        logger.info(f"[CONTENT_GEN_DEBUG] æå–çš„å­—æ®µ - keywords: {keywords}")
        
        # å¤„ç†hashtags
        if isinstance(hashtags, list):
            hashtag_str = ' '.join([f"#{tag.strip('#')}" for tag in hashtags if tag])
        else:
            hashtag_str = str(hashtags) if hashtags else ''
            
        logger.info(f"[CONTENT_GEN_DEBUG] å¤„ç†åçš„hashtag_str: {hashtag_str}")
            
        # æ ¹æ®å†…å®¹ç±»å‹è°ƒæ•´æ ¼å¼
        content_prefix = self._get_content_type_prefix(content_type, language)
        logger.info(f"[CONTENT_GEN_DEBUG] è·å–çš„content_prefix: {content_prefix}")
        
        # æ„å»ºæ¨æ–‡å†…å®¹
        parts = []
        
        if content_prefix:
            parts.append(content_prefix)
        
        if title:
            parts.append(title.strip())
            
        if description and description != title:
            # é™åˆ¶æè¿°é•¿åº¦ï¼Œä¸ºhashtagså’Œå‰ç¼€ç•™ç©ºé—´
            prefix_length = len(content_prefix) + 2 if content_prefix else 0
            max_desc_length = 200 - len(title) - len(hashtag_str) - prefix_length - 10
            if len(description) > max_desc_length:
                description = description[:max_desc_length].rsplit(' ', 1)[0] + '...'
            parts.append(description.strip())
            
        if hashtag_str:
            parts.append(hashtag_str)
            
        tweet_content = '\n\n'.join(parts).strip()
        
        # ç¡®ä¿ä¸è¶…è¿‡Twitterå­—ç¬¦é™åˆ¶ï¼ˆ280å­—ç¬¦ï¼‰
        if len(tweet_content) > 280:
            # ä¼˜å…ˆä¿ç•™æ ‡é¢˜å’Œhashtagsï¼Œå‹ç¼©æè¿°
            if title and hashtag_str:
                available_length = 280 - len(title) - len(hashtag_str) - prefix_length - 8
                if available_length > 20 and description:
                    compressed_desc = description[:available_length].rsplit(' ', 1)[0] + '...'
                    if content_prefix:
                        tweet_content = f"{content_prefix}\n\n{title}\n\n{compressed_desc}\n\n{hashtag_str}"
                    else:
                        tweet_content = f"{title}\n\n{compressed_desc}\n\n{hashtag_str}"
                else:
                    if content_prefix:
                        tweet_content = f"{content_prefix}\n\n{title}\n\n{hashtag_str}"
                    else:
                        tweet_content = f"{title}\n\n{hashtag_str}"
            else:
                tweet_content = tweet_content[:277] + '...'
                
        return tweet_content
    
    def _get_content_type_prefix(self, content_type: str, language: str) -> str:
        """æ ¹æ®å†…å®¹ç±»å‹å’Œè¯­è¨€è·å–å‰ç¼€ã€‚"""
        logger.info(f"[CONTENT_GEN_DEBUG] _get_content_type_prefix è°ƒç”¨")
        logger.info(f"[CONTENT_GEN_DEBUG] content_type: {content_type}, language: {language}")
        
        prefixes = {
            'video': {
                'en': 'ğŸ¥ New Video:',
                'cn': 'ğŸ¥ æ–°è§†é¢‘ï¼š',
                'ja': 'ğŸ¥ æ–°ã—ã„å‹•ç”»ï¼š'
            },
            'article': {
                'en': 'ğŸ“ Article:',
                'cn': 'ğŸ“ æ–‡ç« ï¼š',
                'ja': 'ğŸ“ è¨˜äº‹ï¼š'
            },
            'image': {
                'en': 'ğŸ“¸ Image:',
                'cn': 'ğŸ“¸ å›¾ç‰‡ï¼š',
                'ja': 'ğŸ“¸ ç”»åƒï¼š'
            },
            'audio': {
                'en': 'ğŸµ Audio:',
                'cn': 'ğŸµ éŸ³é¢‘ï¼š',
                'ja': 'ğŸµ éŸ³å£°ï¼š'
            }
        }
        
        result = prefixes.get(content_type, {}).get(language, '')
        logger.info(f"[CONTENT_GEN_DEBUG] _get_content_type_prefix è¿”å›: {result}")
        return result

    def _enhance_with_gemini(self, info: Dict[str, Any], language: str, content_type: str = 'video') -> str:
        """ä½¿ç”¨ Gemini API ç”Ÿæˆæ›´ä¼˜çš„æ¨æ–‡ã€‚"""
        title = info.get('title', 'N/A')
        description = info.get('description', 'N/A')
        keywords = info.get('keywords', [])
        hashtags = info.get('hashtags', [])
        
        # æ ¹æ®å†…å®¹ç±»å‹è°ƒæ•´æç¤ºè¯
        content_type_names = {
            'video': {'en': 'video', 'cn': 'è§†é¢‘', 'ja': 'å‹•ç”»'},
            'article': {'en': 'article', 'cn': 'æ–‡ç« ', 'ja': 'è¨˜äº‹'},
            'image': {'en': 'image', 'cn': 'å›¾ç‰‡', 'ja': 'ç”»åƒ'},
            'audio': {'en': 'audio', 'cn': 'éŸ³é¢‘', 'ja': 'éŸ³å£°'}
        }
        
        content_name = content_type_names.get(content_type, {}).get(language, content_type)
        
        # æ„å»ºè¯­è¨€ç‰¹å®šçš„æç¤ºè¯
        if language == 'cn':
            prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¤¾äº¤åª’ä½“è¥é”€ä¸“å®¶ï¼Œç²¾é€šTwitterçš„è¿è¥ã€‚
è¯·æ ¹æ®ä»¥ä¸‹{content_name}çš„æ ¸å¿ƒå…ƒç´ ï¼Œåˆ›ä½œä¸€æ¡å¸å¼•äººçš„Twitteræ¨æ–‡ã€‚
è¦æ±‚ï¼šè¯­è¨€é£æ ¼è‡ªç„¶ï¼Œèƒ½å¸å¼•ç”¨æˆ·äº’åŠ¨ï¼Œå¹¶åˆç†ä½¿ç”¨æ ‡ç­¾ï¼Œå­—æ•°æ§åˆ¶åœ¨280å­—ç¬¦ä»¥å†…ã€‚

{content_name}æ ‡é¢˜ï¼š{title}
{content_name}æè¿°ï¼š{description}
æ ¸å¿ƒå…³é”®è¯ï¼š{', '.join(keywords) if keywords else 'N/A'}
å»ºè®®æ ‡ç­¾ï¼š{' '.join(hashtags) if hashtags else 'N/A'}

è¯·ç”Ÿæˆä¸­æ–‡æ¨æ–‡å†…å®¹ï¼š
"""
        elif language == 'ja':
            prompt = f"""
ã‚ãªãŸã¯ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã®å°‚é–€å®¶ã§ã€Twitterã®é‹å–¶ã«ç²¾é€šã—ã¦ã„ã¾ã™ã€‚
ä»¥ä¸‹ã®{content_name}ã®æ ¸å¿ƒè¦ç´ ã«åŸºã¥ã„ã¦ã€é­…åŠ›çš„ãªTwitterãƒ„ã‚¤ãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
è¦ä»¶ï¼šè‡ªç„¶ãªè¨€èªã‚¹ã‚¿ã‚¤ãƒ«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿ƒé€²ã€é©åˆ‡ãªãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã®ä½¿ç”¨ã€280æ–‡å­—ä»¥å†…ã€‚

{content_name}ã‚¿ã‚¤ãƒˆãƒ«ï¼š{title}
{content_name}èª¬æ˜ï¼š{description}
ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼š{', '.join(keywords) if keywords else 'N/A'}
æ¨å¥¨ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ï¼š{' '.join(hashtags) if hashtags else 'N/A'}

æ—¥æœ¬èªã®ãƒ„ã‚¤ãƒ¼ãƒˆå†…å®¹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š
"""
        else:  # English
            prompt = f"""
You are a professional social media marketing expert specializing in Twitter operations.
Please create an engaging Twitter tweet based on the following {content_name} elements.
Requirements: Natural language style, encourage user interaction, appropriate use of hashtags, within 280 characters.

{content_name.title()} Title: {title}
{content_name.title()} Description: {description}
Keywords: {', '.join(keywords) if keywords else 'N/A'}
Suggested Hashtags: {' '.join(hashtags) if hashtags else 'N/A'}

Please generate English tweet content:
"""
        
        try:
            response = self.model.generate_content(prompt)
            generated_content = response.text.strip()
            
            # ç¡®ä¿ç”Ÿæˆçš„å†…å®¹ä¸è¶…è¿‡280å­—ç¬¦
            if len(generated_content) > 280:
                generated_content = generated_content[:277] + '...'
                
            return generated_content
            
        except Exception as e:
            logger.error(f"Gemini APIè°ƒç”¨å¤±è´¥: {e}")
            logger.info("å›é€€åˆ°ç›´æ¥æ¨¡å¼ç”Ÿæˆå†…å®¹")
            return self._generate_from_json_directly(info, language, content_type)